{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b35d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycountry\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 55.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pycountry\n",
      "Successfully installed pycountry-24.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-6.4.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-2.11.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\gonca\\appdata\\roaming\\python\\python39\\site-packages (from plotly) (25.0)\n",
      "Downloading plotly-6.4.0-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------  9.7/9.9 MB 46.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 46.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 22.0 MB/s eta 0:00:00\n",
      "Downloading narwhals-2.11.0-py3-none-any.whl (423 kB)\n",
      "Installing collected packages: narwhals, plotly\n",
      "\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   ---------------------------------------- 2/2 [plotly]\n",
      "\n",
      "Successfully installed narwhals-2.11.0 plotly-6.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\gonca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from geopandas) (1.26.4)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.11.1-cp39-cp39-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\gonca\\appdata\\roaming\\python\\python39\\site-packages (from geopandas) (25.0)\n",
      "Requirement already satisfied: pandas>=1.4.0 in c:\\users\\gonca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from geopandas) (2.2.3)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Downloading pyproj-3.6.1-cp39-cp39-win_amd64.whl.metadata (31 kB)\n",
      "Collecting shapely>=2.0.0 (from geopandas)\n",
      "  Downloading shapely-2.0.7-cp39-cp39-win_amd64.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gonca\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gonca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gonca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\gonca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyogrio>=0.7.2->geopandas) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gonca\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.17.0)\n",
      "Downloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "Downloading pyogrio-0.11.1-cp39-cp39-win_amd64.whl (19.2 MB)\n",
      "   ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.1/19.2 MB 11.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 3.1/19.2 MB 10.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 4.7/19.2 MB 7.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 6.3/19.2 MB 8.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 8.4/19.2 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 9.4/19.2 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 11.5/19.2 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 12.6/19.2 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 14.7/19.2 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 16.5/19.2 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.8/19.2 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.2/19.2 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading pyproj-3.6.1-cp39-cp39-win_amd64.whl (6.1 MB)\n",
      "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 2.1/6.1 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.1 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.1/6.1 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.1/6.1 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.1/6.1 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.1/6.1 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.1/6.1 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.2/6.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.1/6.1 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading shapely-2.0.7-cp39-cp39-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 38.1 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely, pyproj, pyogrio, geopandas\n",
      "\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------------------------------------- 0/4 [shapely]\n",
      "   ---------- ----------------------------- 1/4 [pyproj]\n",
      "   ---------- ----------------------------- 1/4 [pyproj]\n",
      "   ---------- ----------------------------- 1/4 [pyproj]\n",
      "   -------------------- ------------------- 2/4 [pyogrio]\n",
      "   -------------------- ------------------- 2/4 [pyogrio]\n",
      "   -------------------- ------------------- 2/4 [pyogrio]\n",
      "   -------------------- ------------------- 2/4 [pyogrio]\n",
      "   ------------------------------ --------- 3/4 [geopandas]\n",
      "   ------------------------------ --------- 3/4 [geopandas]\n",
      "   ------------------------------ --------- 3/4 [geopandas]\n",
      "   ------------------------------ --------- 3/4 [geopandas]\n",
      "   ------------------------------ --------- 3/4 [geopandas]\n",
      "   ------------------------------ --------- 3/4 [geopandas]\n",
      "   ------------------------------ --------- 3/4 [geopandas]\n",
      "   ---------------------------------------- 4/4 [geopandas]\n",
      "\n",
      "Successfully installed geopandas-1.0.1 pyogrio-0.11.1 pyproj-3.6.1 shapely-2.0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting feather-format\n",
      "  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pyarrow>=0.4.0 (from feather-format)\n",
      "  Downloading pyarrow-21.0.0-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pyarrow-21.0.0-cp39-cp39-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 10.7/26.2 MB 56.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.9/26.2 MB 60.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 46.2 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: feather-format\n",
      "  Building wheel for feather-format (pyproject.toml): started\n",
      "  Building wheel for feather-format (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2508 sha256=df03161b1deef68c74e07ff3a3d514f0c91c400e4c9cfe6c423832aeb6dc7710\n",
      "  Stored in directory: c:\\users\\gonca\\appdata\\local\\pip\\cache\\wheels\\e3\\dc\\eb\\3a9468e9322c8284d7a53eab23e7a4bab6f271fff7a5871e2f\n",
      "Successfully built feather-format\n",
      "Installing collected packages: pyarrow, feather-format\n",
      "\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 0/2 [pyarrow]\n",
      "   ---------------------------------------- 2/2 [feather-format]\n",
      "\n",
      "Successfully installed feather-format-0.4.1 pyarrow-21.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'plotly.express' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 71\u001b[0m\n\u001b[0;32m     67\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     69\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.width\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m140\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersões: pandas\u001b[39m\u001b[38;5;124m'\u001b[39m, pd\u001b[38;5;241m.\u001b[39m__version__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequests\u001b[39m\u001b[38;5;124m'\u001b[39m, requests\u001b[38;5;241m.\u001b[39m__version__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplotly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[0;32m     73\u001b[0m DATA_CACHE_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     75\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(DATA_CACHE_DIR, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'plotly.express' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "# Notebook para extrair notícias do GDELT por país e combinar com métricas de impacto de satélites e hubs.\n",
    "\n",
    "# Seção 1: Configuração e Importação de Bibliotecas\n",
    "\n",
    "import sys, os, math, time, json, re, datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imports com instalação preguiçosa apenas se faltarem; evita AttributeErrors parciais\n",
    "try:\n",
    "    import pycountry\n",
    "except ImportError:\n",
    "    import subprocess, sys as _sys\n",
    "    subprocess.run([_sys.executable, '-m', 'pip', 'install', 'pycountry'], check=False)\n",
    "    import pycountry\n",
    "\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly  # para versão correta\n",
    "except ImportError:\n",
    "    import subprocess, sys as _sys\n",
    "    subprocess.run([_sys.executable, '-m', 'pip', 'install', 'plotly'], check=False)\n",
    "    import plotly.express as px\n",
    "    import plotly\n",
    "\n",
    "# Geopandas é pesado; só instala se realmente necessário\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "except ImportError:\n",
    "    import subprocess, sys as _sys\n",
    "    subprocess.run([_sys.executable, '-m', 'pip', 'install', 'geopandas'], check=False)\n",
    "    try:\n",
    "        import geopandas as gpd\n",
    "    except Exception as _e:\n",
    "        gpd = None\n",
    "        print('Geopandas indisponível (opcional):', _e)\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "except ImportError:\n",
    "    import subprocess, sys as _sys\n",
    "    subprocess.run([_sys.executable, '-m', 'pip', 'install', 'ipywidgets'], check=False)\n",
    "    try:\n",
    "        import ipywidgets as widgets\n",
    "    except Exception as _e:\n",
    "        widgets = None\n",
    "        print('ipywidgets indisponível:', _e)\n",
    "\n",
    "# Feather não é crítico; tratamos como opcional\n",
    "try:\n",
    "    import feather\n",
    "except ImportError:\n",
    "    try:\n",
    "        import subprocess, sys as _sys\n",
    "        subprocess.run([_sys.executable, '-m', 'pip', 'install', 'feather-format', 'pyarrow'], check=False)\n",
    "        import feather\n",
    "    except Exception as _e:\n",
    "        feather = None\n",
    "        print('Feather indisponível (usar parquet):', _e)\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 140)\n",
    "\n",
    "# Versões (corrigido plotly.__version__)\n",
    "plotly_version = getattr(plotly, '__version__', 'N/D')\n",
    "print('Versões: pandas', pd.__version__, 'requests', requests.__version__, 'plotly', plotly_version)\n",
    "\n",
    "DATA_CACHE_DIR = 'cache'\n",
    "os.makedirs(DATA_CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 2: Definição de Parâmetros (Países, Datas, Pesos de Impacto)\n",
    "\n",
    "ISO3_COUNTRIES = ['BRA','USA','DEU','FRA','CHN','RUS','ZAF','IND','GBR','CAN']  # pode ajustar\n",
    "\n",
    "DATA_INICIO = datetime.utcnow() - timedelta(days=7)\n",
    "\n",
    "DATA_FIM = datetime.utcnow()\n",
    "\n",
    "FREQUENCIA = 'D'  # 'D' diária, 'W' semanal\n",
    "\n",
    "ALPHA = 0.5  # peso notícias\n",
    "\n",
    "BETA = 0.3   # peso satélites\n",
    "\n",
    "GAMMA = 0.2  # peso hubs\n",
    "\n",
    "\n",
    "\n",
    "def set_pesos(alpha:float, beta:float, gamma:float):\n",
    "\n",
    "    s = alpha+beta+gamma\n",
    "\n",
    "    if not math.isclose(s,1.0):\n",
    "\n",
    "        alpha, beta, gamma = alpha/s, beta/s, gamma/s\n",
    "\n",
    "    return alpha, beta, gamma\n",
    "\n",
    "\n",
    "\n",
    "ALPHA, BETA, GAMMA = set_pesos(ALPHA,BETA,GAMMA)\n",
    "\n",
    "print('Pesos normalizados:', ALPHA, BETA, GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd02c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 3: Funções de Consulta à API GDELT (Eventos por País)\n",
    "\n",
    "GDELT_BASE = \"https://api.gdeltproject.org/api/v2/events/\"\n",
    "\n",
    "\n",
    "\n",
    "def montar_parametros(country_iso3:str, dt_inicio:datetime, dt_fim:datetime, table:'str'='events'):\n",
    "\n",
    "    # GDELT usa formato yyyymmddhhmmss; vamos varrer por dia/intervalos\n",
    "\n",
    "    start = dt_inicio.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "    end = dt_fim.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "    params = {\n",
    "\n",
    "        'query': f\"sourceCountry:{country_iso3}\",  # simplificado; pode expandir (theme, actor, etc.)\n",
    "\n",
    "        'mode': 'EventOnly',\n",
    "\n",
    "        'maxrecords': 250,\n",
    "\n",
    "        'format': 'JSON',\n",
    "\n",
    "        'startdatetime': start,\n",
    "\n",
    "        'enddatetime': end\n",
    "\n",
    "    }\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "def consultar_gdelt(country_iso3:str, dt_inicio:datetime, dt_fim:datetime, retries:int=3, sleep_sec:float=1.5):\n",
    "\n",
    "    params = montar_parametros(country_iso3, dt_inicio, dt_fim)\n",
    "\n",
    "    url = GDELT_BASE + 'api'  # placeholder (ajustar conforme endpoint exato de v2 se diferente)\n",
    "\n",
    "    # Nota: GDELT v2 events real endpoint: https://api.gdeltproject.org/api/v2/summary/summary? (ou tone analysis). Mantido simples.\n",
    "\n",
    "    for tentativa in range(retries):\n",
    "\n",
    "        try:\n",
    "\n",
    "            r = requests.get(GDELT_BASE + 'api', params=params, timeout=30)\n",
    "\n",
    "            if r.status_code == 200:\n",
    "\n",
    "                data = r.json()\n",
    "\n",
    "                # Estrutura fictícia para exemplo; adaptar ao schema verdadeiro.\n",
    "\n",
    "                eventos = data.get('events', [])\n",
    "\n",
    "                if not eventos:\n",
    "\n",
    "                    return pd.DataFrame()\n",
    "\n",
    "                df = pd.json_normalize(eventos)\n",
    "\n",
    "                df['country_iso3_query'] = country_iso3\n",
    "\n",
    "                return df\n",
    "\n",
    "            else:\n",
    "\n",
    "                time.sleep(sleep_sec)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(f'Erro tentativa {tentativa+1} país {country_iso3}:', e)\n",
    "\n",
    "            time.sleep(sleep_sec)\n",
    "\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "def coletar_intervalos(country_iso3:str, ini:datetime, fim:datetime, step_hours:int=6):\n",
    "\n",
    "    atual = ini\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    while atual < fim:\n",
    "\n",
    "        proximo = min(atual + timedelta(hours=step_hours), fim)\n",
    "\n",
    "        dfp = consultar_gdelt(country_iso3, atual, proximo)\n",
    "\n",
    "        if not dfp.empty:\n",
    "\n",
    "            frames.append(dfp)\n",
    "\n",
    "        atual = proximo\n",
    "\n",
    "    if frames:\n",
    "\n",
    "        full = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    else:\n",
    "\n",
    "        full = pd.DataFrame()\n",
    "\n",
    "    return full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 4: Coleta e Consolidação de Eventos GDELT\n",
    "\n",
    "def coletar_todos_paises(paises, ini, fim, step_hours=6):\n",
    "\n",
    "    todos = []\n",
    "\n",
    "    for p in paises:\n",
    "\n",
    "        print('Coletando', p)\n",
    "\n",
    "        dfp = coletar_intervalos(p, ini, fim, step_hours=step_hours)\n",
    "\n",
    "        if not dfp.empty:\n",
    "\n",
    "            todos.append(dfp)\n",
    "\n",
    "    if todos:\n",
    "\n",
    "        full = pd.concat(todos, ignore_index=True)\n",
    "\n",
    "    else:\n",
    "\n",
    "        full = pd.DataFrame()\n",
    "\n",
    "    return full\n",
    "\n",
    "\n",
    "\n",
    "raw_news_df = coletar_todos_paises(ISO3_COUNTRIES, DATA_INICIO, DATA_FIM)\n",
    "\n",
    "print('Registros de notícias obtidos:', len(raw_news_df))\n",
    "\n",
    "\n",
    "\n",
    "# Normalização de datas e país\n",
    "\n",
    "if not raw_news_df.empty:\n",
    "\n",
    "    # Supondo campo timecode (placeholder) ou similar\n",
    "\n",
    "    if 'timecode' in raw_news_df.columns:\n",
    "\n",
    "        raw_news_df['event_dt'] = pd.to_datetime(raw_news_df['timecode'], errors='coerce')\n",
    "\n",
    "    else:\n",
    "\n",
    "        raw_news_df['event_dt'] = DATA_INICIO  # fallback\n",
    "\n",
    "    raw_news_df['country_iso3'] = raw_news_df.get('country_iso3_query')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 5: Limpeza e Normalização dos Dados de Notícias\n",
    "\n",
    "def limpar_noticias(df:pd.DataFrame):\n",
    "\n",
    "    if df.empty:\n",
    "\n",
    "        return df\n",
    "\n",
    "    col_map = {\n",
    "\n",
    "        'GoldsteinScale':'goldstein',\n",
    "\n",
    "        'NumMentions':'num_mentions',\n",
    "\n",
    "        'AvgTone':'avg_tone'\n",
    "\n",
    "    }\n",
    "\n",
    "    for orig, novo in col_map.items():\n",
    "\n",
    "        if orig in df.columns:\n",
    "\n",
    "            df[novo] = pd.to_numeric(df[orig], errors='coerce')\n",
    "\n",
    "        else:\n",
    "\n",
    "            df[novo] = np.nan\n",
    "\n",
    "    # Intensidade de notícia (exemplo simplificado)\n",
    "\n",
    "    df['news_intensity'] = df['goldstein'].fillna(0) * (1 + (df['avg_tone'].fillna(0)/100))\n",
    "\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "news_df = limpar_noticias(raw_news_df.copy())\n",
    "\n",
    "print('Após limpeza:', news_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401505c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 6: Carregamento de Dados de Satélites e Hubs (placeholders)\n",
    "\n",
    "# Aqui simulamos dados; na integração real fazer leitura de Postgres ou arquivos produzidos por dbt.\n",
    "\n",
    "def carregar_satellites():\n",
    "\n",
    "    # Simulado: métricas diárias por país\n",
    "\n",
    "    dias = pd.date_range(DATA_INICIO.date(), DATA_FIM.date(), freq='D')\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for p in ISO3_COUNTRIES:\n",
    "\n",
    "        for d in dias:\n",
    "\n",
    "            rows.append({'country_iso3':p,'date':d,'sat_value':np.random.rand()*100})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "def carregar_hubs():\n",
    "\n",
    "    dias = pd.date_range(DATA_INICIO.date(), DATA_FIM.date(), freq='D')\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for p in ISO3_COUNTRIES:\n",
    "\n",
    "        for d in dias:\n",
    "\n",
    "            rows.append({'country_iso3':p,'date':d,'hub_value':np.random.rand()*50})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "sat_df = carregar_satellites()\n",
    "\n",
    "hub_df = carregar_hubs()\n",
    "\n",
    "print('Satélites shape', sat_df.shape, 'Hubs shape', hub_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 7: Cálculo da Métrica de Impacto Integrada\n",
    "\n",
    "def normalizar_coluna(df, col):\n",
    "\n",
    "    if df[col].nunique() <= 1:\n",
    "\n",
    "        df[col+'_norm'] = 0.0\n",
    "\n",
    "        return df\n",
    "\n",
    "    mn, mx = df[col].min(), df[col].max()\n",
    "\n",
    "    df[col+'_norm'] = (df[col]-mn)/(mx-mn)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def agregar_noticias(df_news:pd.DataFrame, freq:str='D'):\n",
    "\n",
    "    if df_news.empty:\n",
    "\n",
    "        return pd.DataFrame(columns=['country_iso3','date','news_intensity_sum','news_intensity_mean'])\n",
    "\n",
    "    df_news['date'] = df_news['event_dt'].dt.date\n",
    "\n",
    "    agg = df_news.groupby(['country_iso3','date']).agg(news_intensity_sum=('news_intensity','sum'), news_intensity_mean=('news_intensity','mean')).reset_index()\n",
    "\n",
    "    return agg\n",
    "\n",
    "\n",
    "\n",
    "news_agg = agregar_noticias(news_df, FREQUENCIA)\n",
    "\n",
    "\n",
    "\n",
    "# Convert date column types\n",
    "\n",
    "if not news_agg.empty:\n",
    "\n",
    "    news_agg['date'] = pd.to_datetime(news_agg['date'])\n",
    "\n",
    "\n",
    "\n",
    "# Normalizar sat e hub por país+dia\n",
    "\n",
    "sat_norm = sat_df.copy()\n",
    "\n",
    "hub_norm = hub_df.copy()\n",
    "\n",
    "sat_norm = normalizar_coluna(sat_norm, 'sat_value')\n",
    "\n",
    "hub_norm = normalizar_coluna(hub_norm, 'hub_value')\n",
    "\n",
    "\n",
    "\n",
    "# Merge geral\n",
    "\n",
    "impact_base = news_agg.merge(sat_norm, on=['country_iso3','date'], how='left').merge(hub_norm, on=['country_iso3','date'], how='left')\n",
    "\n",
    "impact_base['sat_metric'] = impact_base['sat_value_norm'].fillna(0)\n",
    "\n",
    "impact_base['hub_metric'] = impact_base['hub_value_norm'].fillna(0)\n",
    "\n",
    "impact_base['news_metric'] = normalizar_coluna(impact_base.copy(), 'news_intensity_sum')['news_intensity_sum_norm'] if not impact_base.empty else []\n",
    "\n",
    "\n",
    "\n",
    "if not impact_base.empty:\n",
    "\n",
    "    impact_base['impact_raw'] = ALPHA*impact_base['news_metric'] + BETA*impact_base['sat_metric'] + GAMMA*impact_base['hub_metric']\n",
    "\n",
    "    impact_base = normalizar_coluna(impact_base, 'impact_raw')\n",
    "\n",
    "    impact_base.rename(columns={'impact_raw_norm':'impact_score'}, inplace=True)\n",
    "\n",
    "else:\n",
    "\n",
    "    impact_base['impact_score'] = []\n",
    "\n",
    "\n",
    "\n",
    "print('Impact base size:', impact_base.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ff46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 8: Agregação Temporal e por País\n",
    "\n",
    "def agregacao_final(df:pd.DataFrame, freq:str='D'):\n",
    "\n",
    "    if df.empty:\n",
    "\n",
    "        return pd.DataFrame(columns=['country_iso3','date','impact_score_mean','impact_score_sum'])\n",
    "\n",
    "    df['date_period'] = df['date']\n",
    "\n",
    "    agg = df.groupby(['country_iso3','date_period']).agg(impact_score_mean=('impact_score','mean'), impact_score_sum=('impact_score','sum')).reset_index()\n",
    "\n",
    "    return agg\n",
    "\n",
    "\n",
    "\n",
    "final_agg = agregacao_final(impact_base, FREQUENCIA)\n",
    "\n",
    "print('Final aggregation shape:', final_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5066fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 9: Geração de Tabelas Resumo\n",
    "\n",
    "def ranking_paises(df:pd.DataFrame, top:int=15):\n",
    "\n",
    "    if df.empty:\n",
    "\n",
    "        return pd.DataFrame(columns=['country_iso3','impact_score_mean'])\n",
    "\n",
    "    rank = df.groupby('country_iso3').impact_score_mean.mean().reset_index().sort_values('impact_score_mean', ascending=False)\n",
    "\n",
    "    return rank.head(top)\n",
    "\n",
    "\n",
    "\n",
    "ranking_df = ranking_paises(final_agg, 15)\n",
    "\n",
    "print('Ranking de países (top 15):')\n",
    "\n",
    "display(ranking_df.style.background_gradient(cmap='viridis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eda686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 10: Visualização Geoespacial (Mapas Coropléticos)\n",
    "\n",
    "def carregar_mapa_mundo():\n",
    "\n",
    "    try:\n",
    "\n",
    "        world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "        # Ajustar ISO codes\n",
    "\n",
    "        world = world.rename(columns={'iso_a3':'country_iso3'})\n",
    "\n",
    "        return world\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print('Erro carregando mapa mundial:', e)\n",
    "\n",
    "        return gpd.GeoDataFrame()\n",
    "\n",
    "\n",
    "\n",
    "world = carregar_mapa_mundo()\n",
    "\n",
    "if not world.empty and not final_agg.empty:\n",
    "\n",
    "    latest = final_agg.sort_values('date_period').groupby('country_iso3').tail(1)\n",
    "\n",
    "    geo_df = world.merge(latest, on='country_iso3', how='left')\n",
    "\n",
    "    fig_map = px.choropleth(geo_df.to_crs('EPSG:4326'), locations='country_iso3', color='impact_score_mean', hover_name='country_iso3', projection='natural earth', title='Impacto Integrado por País (Último Período)')\n",
    "\n",
    "    fig_map.show()\n",
    "\n",
    "else:\n",
    "\n",
    "    print('Mapa não gerado (dados insuficientes).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb270d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 11: Visualizações Temporais (Séries / Heatmaps)\n",
    "\n",
    "def serie_temporal(df:pd.DataFrame, pais:str):\n",
    "\n",
    "    d = df[df.country_iso3==pais].sort_values('date_period')\n",
    "\n",
    "    if d.empty:\n",
    "\n",
    "        print('Sem dados para', pais)\n",
    "\n",
    "        return None\n",
    "\n",
    "    fig = px.line(d, x='date_period', y='impact_score_mean', title=f'Série de Impacto - {pais}')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "def heatmap_paises(df:pd.DataFrame):\n",
    "\n",
    "    if df.empty: return\n",
    "\n",
    "    pivot = df.pivot_table(index='country_iso3', columns='date_period', values='impact_score_mean', aggfunc='mean')\n",
    "\n",
    "    pivot = pivot.fillna(0)\n",
    "\n",
    "    fig = px.imshow(pivot.values, labels=dict(x='Período', y='País', color='Impacto'), x=pivot.columns, y=pivot.index, aspect='auto', title='Heatmap Impacto por País x Período')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "if not final_agg.empty:\n",
    "\n",
    "    heatmap_paises(final_agg)\n",
    "\n",
    "    serie_temporal(final_agg, ISO3_COUNTRIES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 12: Dashboard Interativo com ipywidgets (Atualizado para fonte real/placeholder)\n",
    "\n",
    "pais_widget = widgets.SelectMultiple(options=ISO3_COUNTRIES, value=tuple(ISO3_COUNTRIES[:3]), description='Países')\n",
    "\n",
    "alpha_widget = widgets.FloatSlider(min=0,max=1,step=0.05,value=ALPHA,description='Alpha Notícias')\n",
    "\n",
    "beta_widget = widgets.FloatSlider(min=0,max=1,step=0.05,value=BETA,description='Beta Sat')\n",
    "\n",
    "gamma_widget = widgets.FloatSlider(min=0,max=1,step=0.05,value=GAMMA,description='Gamma Hub')\n",
    "\n",
    "fonte_widget = widgets.ToggleButtons(options=['placeholder','real'], value='real' if 'real_base' in globals() and not real_base.empty else 'placeholder', description='Fonte')\n",
    "\n",
    "out_dashboard = widgets.Output()\n",
    "\n",
    "\n",
    "\n",
    "def recalcular(_):\n",
    "\n",
    "    with out_dashboard:\n",
    "\n",
    "        out_dashboard.clear_output()\n",
    "\n",
    "        a,b,g = set_pesos(alpha_widget.value, beta_widget.value, gamma_widget.value)\n",
    "\n",
    "        if fonte_widget.value == 'real' and 'real_base' in globals() and not real_base.empty:\n",
    "\n",
    "            base_df = real_base.copy()\n",
    "\n",
    "            # Já temos event_cnt_norm, tone_norm, hub_events_norm; recalcular impacto com novos pesos\n",
    "\n",
    "            base_df['impact_raw'] = a*base_df['event_cnt_norm'] + b*base_df['tone_norm'] + g*base_df['hub_events_norm']\n",
    "\n",
    "            base_df['impact_score'] = safe_norm(base_df['impact_raw'])\n",
    "\n",
    "            base_df['date_period'] = pd.to_datetime(base_df['date'])\n",
    "\n",
    "            sel = list(pais_widget.value)\n",
    "\n",
    "            base_df = base_df[base_df.country_iso3.isin(sel)]\n",
    "\n",
    "            agg = base_df.groupby(['country_iso3','date_period']).impact_score.mean().reset_index(name='impact_score_mean')\n",
    "\n",
    "        else:\n",
    "\n",
    "            if 'impact_base' not in globals() or impact_base.empty:\n",
    "\n",
    "                print('Sem dados placeholder disponíveis.')\n",
    "\n",
    "                return\n",
    "\n",
    "            temp = impact_base.copy()\n",
    "\n",
    "            temp['impact_raw'] = a*temp['news_metric'] + b*temp['sat_metric'] + g*temp['hub_metric']\n",
    "\n",
    "            temp = normalizar_coluna(temp, 'impact_raw')\n",
    "\n",
    "            temp.rename(columns={'impact_raw_norm':'impact_score'}, inplace=True)\n",
    "\n",
    "            sel = list(pais_widget.value)\n",
    "\n",
    "            temp = temp[temp.country_iso3.isin(sel)]\n",
    "\n",
    "            agg = agregacao_final(temp, FREQUENCIA)\n",
    "\n",
    "        if agg.empty:\n",
    "\n",
    "            print('Sem dados após filtro.')\n",
    "\n",
    "            return\n",
    "\n",
    "        fig = px.line(agg, x='date_period', y='impact_score_mean', color='country_iso3', title=f'Impacto ({fonte_widget.value})')\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        rank = agg.groupby('country_iso3').impact_score_mean.mean().reset_index().sort_values('impact_score_mean', ascending=False)\n",
    "\n",
    "        display(rank.head(len(list(pais_widget.value))))\n",
    "\n",
    "\n",
    "\n",
    "for w in [pais_widget, alpha_widget, beta_widget, gamma_widget, fonte_widget]:\n",
    "\n",
    "    w.observe(recalcular, names='value')\n",
    "\n",
    "\n",
    "\n",
    "display(widgets.HBox([pais_widget, widgets.VBox([alpha_widget,beta_widget,gamma_widget,fonte_widget])]))\n",
    "\n",
    "display(out_dashboard)\n",
    "\n",
    "recalcular(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d855ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 13: Exportação dos Resultados (CSV / Parquet)\n",
    "\n",
    "timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "def exportar(df:pd.DataFrame, nome_base:str):\n",
    "\n",
    "    if df.empty:\n",
    "\n",
    "        print('Nada para exportar em', nome_base)\n",
    "\n",
    "        return\n",
    "\n",
    "    csv_path = f'{nome_base}_{timestamp}.csv'\n",
    "\n",
    "    parquet_path = f'{nome_base}_{timestamp}.parquet'\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    try:\n",
    "\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print('Falha exportar parquet (instale pyarrow):', e)\n",
    "\n",
    "    print('Exportado:', csv_path, parquet_path)\n",
    "\n",
    "\n",
    "\n",
    "exportar(final_agg, 'impacto_pais_periodo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a5efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção 14: Rotina de Agendamento / Execução Automatizada (Opcional)\n",
    "\n",
    "def rotina_principal():\n",
    "\n",
    "    inicio = time.time()\n",
    "\n",
    "    # Exemplo simplificado: recomputar impacto usando pesos correntes\n",
    "\n",
    "    if impact_base.empty:\n",
    "\n",
    "        print('Sem base para rotina.')\n",
    "\n",
    "        return\n",
    "\n",
    "    temp = impact_base.copy()\n",
    "\n",
    "    temp['impact_raw'] = ALPHA*temp['news_metric'] + BETA*temp['sat_metric'] + GAMMA*temp['hub_metric']\n",
    "\n",
    "    temp = normalizar_coluna(temp, 'impact_raw')\n",
    "\n",
    "    dur = time.time() - inicio\n",
    "\n",
    "    print(f'Rotina concluída em {dur:.2f}s. Linhas processadas: {len(temp)}')\n",
    "\n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    rotina_principal()\n",
    "\n",
    "\n",
    "\n",
    "# Fim do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1545db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integração Postgres: Conexão e Carregamento de hub_event / sat_event (Nova Seção)\n",
    "\n",
    "import sqlalchemy as sa\n",
    "\n",
    "from sqlalchemy.engine import URL\n",
    "\n",
    "\n",
    "\n",
    "PG_HOST = os.getenv('PGHOST','postgres')\n",
    "\n",
    "PG_DB   = os.getenv('PGDATABASE','gdelt')\n",
    "\n",
    "PG_USER = os.getenv('PGUSER','gdelt_user')\n",
    "\n",
    "PG_PWD  = os.getenv('PGPASSWORD','gdelt_pass')\n",
    "\n",
    "PG_PORT = os.getenv('PGPORT','5432')\n",
    "\n",
    "PG_SCHEMA = 'silver'\n",
    "\n",
    "\n",
    "\n",
    "conn_url = URL.create(\n",
    "\n",
    "    drivername='postgresql+psycopg2',\n",
    "\n",
    "    username=PG_USER,\n",
    "\n",
    "    password=PG_PWD,\n",
    "\n",
    "    host=PG_HOST,\n",
    "\n",
    "    port=PG_PORT,\n",
    "\n",
    "    database=PG_DB\n",
    "\n",
    ")\n",
    "\n",
    "engine = sa.create_engine(conn_url)\n",
    "\n",
    "\n",
    "\n",
    "def load_table(table_name:str):\n",
    "\n",
    "    full_name = f'{PG_SCHEMA}.{table_name}'\n",
    "\n",
    "    try:\n",
    "\n",
    "        df = pd.read_sql(f'SELECT * FROM {full_name} LIMIT 200000', engine)\n",
    "\n",
    "        print(f'Carregado {len(df)} linhas de {full_name}')\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print('Erro carregando', full_name, e)\n",
    "\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "hub_event_df = load_table('hub_event')\n",
    "\n",
    "sat_event_df = load_table('sat_event')\n",
    "\n",
    "\n",
    "\n",
    "# Parsing de localização / países a partir de sat_event.locations\n",
    "\n",
    "def extract_country_codes(loc_str):\n",
    "\n",
    "    if not isinstance(loc_str,str) or loc_str.strip()=='' :\n",
    "\n",
    "        return []\n",
    "\n",
    "    parts = loc_str.split(';')\n",
    "\n",
    "    codes = []\n",
    "\n",
    "    for p in parts:\n",
    "\n",
    "        # Estrutura comum GDELT LOC: geonameid#type#countrycode#adm1code#latitude#longitude#featureid\n",
    "\n",
    "        segs = p.split('#')\n",
    "\n",
    "        if len(segs) >= 3:\n",
    "\n",
    "            cc = segs[2].upper()\n",
    "\n",
    "            if re.fullmatch(r'[A-Z]{2,3}', cc):\n",
    "\n",
    "                codes.append(cc)\n",
    "\n",
    "    return list(set(codes))\n",
    "\n",
    "\n",
    "\n",
    "if 'locations' in sat_event_df.columns:\n",
    "\n",
    "    sat_event_df['country_codes'] = sat_event_df['locations'].apply(extract_country_codes)\n",
    "\n",
    "    sat_exploded = sat_event_df.explode('country_codes')\n",
    "\n",
    "else:\n",
    "\n",
    "    sat_event_df['country_codes'] = []\n",
    "\n",
    "    sat_exploded = sat_event_df\n",
    "\n",
    "\n",
    "\n",
    "# Função para mapear ISO2->ISO3 quando necessário\n",
    "\n",
    "iso2_to_iso3 = {c.alpha_2: c.alpha_3 for c in pycountry.countries}\n",
    "\n",
    "def to_iso3(code):\n",
    "\n",
    "    if code is None or not isinstance(code,str):\n",
    "\n",
    "        return None\n",
    "\n",
    "    code = code.upper()\n",
    "\n",
    "    if len(code)==2 and code in iso2_to_iso3:\n",
    "\n",
    "        return iso2_to_iso3[code]\n",
    "\n",
    "    if len(code)==3:\n",
    "\n",
    "        return code\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "sat_exploded['country_iso3'] = sat_exploded['country_codes'].apply(to_iso3)\n",
    "\n",
    "sat_exploded = sat_exploded[~sat_exploded['country_iso3'].isna()]\n",
    "\n",
    "\n",
    "\n",
    "# Derivar data (date_event já existe em sat_event). Caso contrário usar load_date\n",
    "\n",
    "date_col = 'date_event' if 'date_event' in sat_exploded.columns else 'load_date'\n",
    "\n",
    "sat_exploded['date'] = pd.to_datetime(sat_exploded[date_col]).dt.date\n",
    "\n",
    "\n",
    "\n",
    "# Métricas agregadas de satélite (exemplo: média tone e polarity, contagem eventos)\n",
    "\n",
    "sat_metrics = sat_exploded.groupby(['country_iso3','date']).agg(\n",
    "\n",
    "    tone_mean=('tone','mean'),\n",
    "\n",
    "    polarity_mean=('polarity','mean'),\n",
    "\n",
    "    event_cnt=('event_hk','count')\n",
    "\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# Hub_event agregação (apenas contagem distinta de eventos por país derivado cruzando com satélite)\n",
    "\n",
    "# hub_event não tem países -> usamos join por event_hk para trazer same country mapping\n",
    "\n",
    "if not hub_event_df.empty and 'event_hk' in hub_event_df.columns and 'event_hk' in sat_exploded.columns:\n",
    "\n",
    "    hub_with_country = hub_event_df.merge(sat_exploded[['event_hk','country_iso3','date']], on='event_hk', how='left')\n",
    "\n",
    "    hub_metrics = hub_with_country.groupby(['country_iso3','date']).agg(hub_events=('event_hk','nunique')).reset_index()\n",
    "\n",
    "else:\n",
    "\n",
    "    hub_metrics = pd.DataFrame(columns=['country_iso3','date','hub_events'])\n",
    "\n",
    "\n",
    "\n",
    "# Combinar métricas reais em base integrada\n",
    "\n",
    "real_base = sat_metrics.merge(hub_metrics, on=['country_iso3','date'], how='left')\n",
    "\n",
    "real_base['hub_events'] = real_base['hub_events'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# Normalizações\n",
    "\n",
    "def safe_norm(series):\n",
    "\n",
    "    if series.empty: return series\n",
    "\n",
    "    mn, mx = series.min(), series.max()\n",
    "\n",
    "    if mn==mx: return pd.Series([0]*len(series), index=series.index)\n",
    "\n",
    "    return (series-mn)/(mx-mn)\n",
    "\n",
    "\n",
    "\n",
    "real_base['tone_norm'] = safe_norm(real_base['tone_mean'].fillna(0))\n",
    "\n",
    "real_base['polarity_norm'] = safe_norm(real_base['polarity_mean'].fillna(0))\n",
    "\n",
    "real_base['event_cnt_norm'] = safe_norm(real_base['event_cnt'])\n",
    "\n",
    "real_base['hub_events_norm'] = safe_norm(real_base['hub_events'])\n",
    "\n",
    "\n",
    "\n",
    "# Recalcular impacto usando: news_metric ~ event_cnt_norm, sat_metric ~ tone_norm, hub_metric ~ hub_events_norm (exemplo)\n",
    "\n",
    "real_base['impact_raw'] = ALPHA*real_base['event_cnt_norm'] + BETA*real_base['tone_norm'] + GAMMA*real_base['hub_events_norm']\n",
    "\n",
    "real_base['impact_score'] = safe_norm(real_base['impact_raw'])\n",
    "\n",
    "\n",
    "\n",
    "print('Real base shape:', real_base.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Preview ranking real\n",
    "\n",
    "real_ranking = real_base.groupby('country_iso3').impact_score.mean().reset_index().sort_values('impact_score', ascending=False)\n",
    "\n",
    "display(real_ranking.head(15))\n",
    "\n",
    "\n",
    "\n",
    "# Flag para dashboard usar dados reais\n",
    "\n",
    "USE_REAL_DATA = True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
